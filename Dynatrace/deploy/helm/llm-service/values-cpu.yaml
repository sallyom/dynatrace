servingRuntime:
  image: public.ecr.aws/q9t5s3a7/vllm-cpu-release-repo@sha256:6b0d6af534a3c2a24fbcbd0e5e919f9f215be73fdf799a7bbd324178956cb7df

models:
  llama-3-2-1b-instruct:
    id: meta-llama/Llama-3.2-1B-Instruct
    enabled: false
    inferenceService:
      resources: {}
      args:
      - --enable-auto-tool-choice
      - --chat-template
      - /workspace/vllm/examples/tool_chat_template_llama3.2_json.jinja
      - --tool-call-parser
      - llama3_json
      - --max-model-len
      - "30544"

  llama-guard-3-1b:
    id: meta-llama/Llama-Guard-3-1B
    enabled: false
    inferenceService:
      resources: {}
      args:
      - --max-model-len
      - "14336"
